\chapter{Device Architecture} \label{ch:device architecture}

CPUs and GPUs each offer advantages for different computational tasks. Multi-core CPUs offer independent cores which are effectively discrete processors. GPUs offer larger-scale parallelization, but require strong data and code coherence in order to achieve acceptable performance.

\section{CPU}

Most desktop PC users typically run many different applications in parallel: a web browser, music player, word processor and email client are a common combination. Multi-core CPUs facilitate this by providing separate ALUs, register files and cache, minimizing dependencies between cores on the same physical device. 

\section{GPU}

Unlike CPUs, GPUs are capable of running thousands of threads in parallel using a SIMD (single-instruction, multiple-data) model. This architecture allows rapid processing of large datasets wherein each datum exhibits little or no interdependence.  This independence is crucial to GPU performance as detailed in \autoref{sec:simd}.

\subsection{SIMD}\label{sec:simd}

In a SIMD\cite{Massingill:2007:SAP:1772070.1772078} architecture, a core may consist of a single instruction control unit with multiple ALUs. Separate threads load distinct data into thread-specific register banks. The ALUs execute identical operations on each thread's registers simultaneously. In this way, each register bank is analogous to a CPU thread. Where a CPU thread comprises potentially-distinct code and data, concurrent SIMD threads differ only in the data that they manipulate.  However, since the same instruction must be executed on all register sets at every step, this design is less flexible than a typical CPU architecture where each core is truly independent. 

That said, the SIMD approach provides significant benefits, including:

\begin{itemize}
	\item Smaller die area due to reduced component count.
	\item Lower TDP.
	\item Improved code caching. Since all cores execute the same instruction, it is not necessary for each core to maintain a separate instruction cache. 
\end{itemize}

\section{Resource Limitations}

When comparing CPUs and GPUs, it is important to consider available resources. Modern GPUs may provide 32GB (or more) of RAM.  High-end devices provide on-board solid-state FLASH storage in excess of 1TB. However, if a simulation requires more memory than is available on the device, the application will be responsible for swapping data between the GPU and the host system over the PCIe bus. Due to the relatively slow speed of the PCIe bus versus the speed of onboard memory, this incurs a severe performance penalty which can negate the speedup provided by the GPU. 

In contrast, CPUs potentially have much more memory available. A modern desktop computer may be equipped with more than 1TB of RAM. Operating systems such as Microsoft Windows, Linux \& MacOS offer the ability to swap RAM contents to disk when an application's requirements exceed available RAM. While this process incurs its own performance penalty, it makes possible simulation of domains that exceed GPU memory constraints.

\iffalse
I'd like a wrapping up paragraph here to say that for the problem you are looking at GPU's make sense as a choice and why (likely get enough of them that cache memory isn't swapped often...) or some other tie back to the work.
\fi

For FDTD, multiple GPUs may be leveraged to overcome these limitations. In the case where a simulation requires more memory than is available on the GPU, the domain may be divided into subdomains which are assigned to dedicated devices. At the end of each $E$ or $H$ field calculation, field values lying on the border between subdomains may be copied from the GPU to the host, and then sent to the GPU responsible for the adjacent subdomain. This approach significantly reduces the quantity of data that must be transferred over the PCIe bus and therefore reduces any performance loss due to data transfer. 






