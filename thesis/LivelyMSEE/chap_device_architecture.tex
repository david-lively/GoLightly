\chapter{Device Architecture} \label{ch:device architecture}

CPUs and GPUs each offer advantages for different computational tasks. Multi-core CPUs offer independent cores which are effectively discrete processors. GPUs, however, offer large-scale parallelization, but require strong data and code coherence in order to achieve acceptable performance.


\section{CPU}

Users typically run many different applications in parallel: a web browser, music player, word processor and email client are a common combination.

In a modern multi-core CPU, each core provides a dedicated ALU and register set. This allows each core to operate as an independent device. This architecture is advantageous when the device is required to perform disparate operations.

However, this approach also introduces some performance limitations. If we wish to perform identical operations on large datasets, we are limited to 4-8 threads. The same processor that excels at executing many different tasks at the same time performs sub-optimally. 

When running FDTD on a CPU, each core's ALU executes essentially the same operations on a dedicated register set. Each ALU performs the same operation at the same time, indicating that the additional ALUs are redundant. Thus, the flexible, general-purpose nature of a CPU becomes a liability.

\section{GPU}

Unlike CPUs, GPUs are capable of running thousands of threads in parallel using a SIMD (single-instruction, multiple-data) model. This architecture is allows rapid processing of large datasets wherein each datum exhibits little or no interdependence. 

This independence is crucial to performant GPU-based applications, as detailed in \autoref{sec:simd}.

\subsection{SIMD}\label{sec:simd}

In a SIMD\cite{Massingill:2007:SAP:1772070.1772078} architecture, a core may consist of a single ALU, with multiple register banks. Separate "threads" load different data into dedicated register banks. The ALU executes identitical operations on all registers simultaneously. In this way, each register bank is analagous to a CPU "thread." However, since the same instruction must be executed on all register sets at every step, this design is not as flexible as a system where each core is truly independent.

That said, the approach provides some benefits and limitations:

\begin{itemize}
	\item Fewer components are required per core since fewer ALUs are required. Leads to reduced die space requirements.
	\item Better code caching. A single ALU, and corresponding cache, are used for many threads, eliminating the need to load or monitor code cache behavior per thread.
	\item Smaller footprint. Use of fewer components allows more cores to be placed within a given physical space. 
\end{itemize}


\subsection{FDTD in SIMD}

FDTD's leap-frog update method, whereby E fields and H fields are successively calculated, is well-suited to a GPU implementation. E field values depend on adjacent H field values, and visa-versa. Since the E-field update equation requires knowledge only of the H field state and previous E field state, each field component can be calculated independently with no opportunity for a pipeline stall or race condition. 




