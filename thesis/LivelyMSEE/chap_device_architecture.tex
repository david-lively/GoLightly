\chapter{Device Architecture} \label{ch:device architecture}

CPUs and GPUs each offer advantages for different computational tasks. Multi-core CPUs offer independent cores which are effectively discrete processors. GPUs offer larger-scale parallelization, but require strong data and code coherence in order to achieve acceptable performance.

\section{CPU}

Users typically run many different applications in parallel: a web browser, music player, word processor and email client are a common combination. Multicore CPUs facilitate this by providing separate ALUs, register files and cache, minimizing dependencies between cores on the same physical device. 

\section{GPU}

Unlike CPUs, GPUs are capable of running thousands of threads in parallel using a SIMD (single-instruction, multiple-data) model. This architecture allows rapid processing of large datasets wherein each datum exhibits little or no interdependence.  This independence is crucial to GPU performance as detailed in \autoref{sec:simd}.

\subsection{SIMD}\label{sec:simd}

In a SIMD\cite{Massingill:2007:SAP:1772070.1772078} architecture, a core may consist of a single ALU with multiple register files. Separate threads load different data into dedicated register banks. The ALU executes identitical operations on each lane's registers simultaneously. In this way, each register bank is analagous to a CPU "thread." However, since the same instruction must be executed on all register sets at every step, this design is less flexible than a system where each core is truly independent. 

That said, the SIMD approach provides some benefits, including:

\begin{itemize}
	\item Fewer components are required per core since fewer ALUs are required. Leads to reduced die space requirements.
	\item Better code caching. A single ALU, and corresponding cache, are used for many threads. This simplifies cache controller architecture.
\end{itemize}





